{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBi0giG_654h"
   },
   "source": [
    "# Random Forest\n",
    "\n",
    "Concept behind Random Forests - \"A large number of relatively uncorrelated models (trees) operating as a committee will outperform any of the individual constituent models.\"\n",
    "\n",
    "The low correlation between models is the key.\n",
    "\n",
    "The reason for this wonderful effect is that the trees protect each other from their individual errors (as long as they don’t constantly all err in the same direction).\n",
    "\n",
    "---\n",
    "So how does random forest ensure that the behavior of each individual tree is not too correlated with the behavior of any of the other trees in the model? It uses the following two methods:\n",
    "\n",
    "Bagging (Bootstrap Aggregation) — Decisions trees are very sensitive to the data they are trained on — small changes to the training set can result in significantly different tree structures. Random forest takes advantage of this by allowing each individual tree to randomly sample from the dataset with replacement, resulting in different trees. This process is known as bagging.\n",
    "\n",
    "---\n",
    "The random forest is a classification algorithm consisting of many decisions trees. It uses bagging and feature randomness when building each individual tree to try to create an uncorrelated forest of trees whose prediction by committee is more accurate than that of any individual tree.\n",
    "\n",
    "---\n",
    "### Advantages:\n",
    "\n",
    "* Random forests is considered as a highly accurate and robust method because of the number of decision trees participating in the process.\n",
    "* It does not suffer from the overfitting problem. The main reason is that it takes the average of all the predictions, which cancels out the biases.\n",
    "* The algorithm can be used in both classification and regression problems.\n",
    "* Random forests can also handle missing values. There are two ways to handle these: using median values to replace continuous variables, and computing the proximity-weighted average of missing values.\n",
    "* You can get the relative feature importance, which helps in selecting the most contributing features for the classifier.\n",
    "\n",
    "### Disadvantages:\n",
    "* Random forests is slow in generating predictions because it has multiple decision trees. Whenever it makes a prediction, all the trees in the forest have to make a prediction for the same given input and then perform voting on it. This whole process is time-consuming.\n",
    "* The model is difficult to interpret compared to a decision tree, where you can easily make a decision by following the path in the tree.\n",
    "\n",
    "### Random Forests vs Decision Trees\n",
    "* Random forests is a set of multiple decision trees.\n",
    "* Deep decision trees may suffer from overfitting, but random forests prevents overfitting by creating trees on random subsets.\n",
    "* Decision trees are computationally faster.\n",
    "* Random forests is difficult to interpret, while a decision tree is easily interpretable and can be converted to rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jpYSSM31CBgH"
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6NnZJ2lECDk1",
    "outputId": "d8896729-78cc-4063-b2fe-e7db69a2d308"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': '/home/rishabh/myfiles/venv/lib/python3.8/site-packages/sklearn/datasets/data/iris.csv'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HHBkAZ0FCEez",
    "outputId": "313ddfca-bcda-4db3-96a8-6938497c756b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "print(iris.target_names)\n",
    "print(iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BPbYviidCKyk",
    "outputId": "04c635ee-d672-431c-a6be-2814c4844b38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(iris.data[0:5])\n",
    "print(iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "0-C-SNlmCPNk",
    "outputId": "f25b5caa-dd44-44fb-d679-b72925d2d703"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length  sepal width  petal length  petal width  species\n",
       "0           5.1          3.5           1.4          0.2        0\n",
       "1           4.9          3.0           1.4          0.2        0\n",
       "2           4.7          3.2           1.3          0.2        0\n",
       "3           4.6          3.1           1.5          0.2        0\n",
       "4           5.0          3.6           1.4          0.2        0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data=pd.DataFrame({\n",
    "    'sepal length':iris.data[:,0],\n",
    "    'sepal width':iris.data[:,1],\n",
    "    'petal length':iris.data[:,2],\n",
    "    'petal width':iris.data[:,3],\n",
    "    'species':iris.target\n",
    "})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "jPWvsRZDCTDE"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=data[['sepal length', 'sepal width', 'petal length', 'petal width']]  # Features\n",
    "y=data['species']  # Labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d8pzOiOXCYvR"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pjtO8hQbCbkB",
    "outputId": "64f1e8e5-b32b-4720-d155-a1fc0b7be0a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zmWtYZZiCdnR",
    "outputId": "e6012c3f-49e7-43a7-88c3-affdb0e7663b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[3, 5, 4, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8WrhuxmqChQh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UP6ucpztCjvj"
   },
   "source": [
    "Finding Important Features in the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n3gCinKvCmIw",
    "outputId": "48793937-f528-4dfc-ebf9-5b2bc4c42bb3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WcRG9tBMCmjh",
    "outputId": "8c77c4d2-0762-498c-f918-e80ccc344d62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "petal width (cm)     0.501269\n",
       "petal length (cm)    0.408000\n",
       "sepal length (cm)    0.081045\n",
       "sepal width (cm)     0.009685\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "feature_imp = pd.Series(clf.feature_importances_,index=iris.feature_names).sort_values(ascending=False)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "ekpG1TjBCp9z",
    "outputId": "4781504a-0d51-4a19-9bd7-0b51792168d6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "# Creating a bar plot\n",
    "sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "# Add labels to your graph\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title(\"Visualizing Important Features\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sO9M875DCujz"
   },
   "outputs": [],
   "source": [
    "# Import train_test_split function\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "# Split dataset into features and labels\n",
    "X=data[['petal length', 'petal width','sepal length']]  # Removed feature \"sepal length\"\n",
    "y=data['species']                                       \n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.70, random_state=5) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A_n-fGkECxjz",
    "outputId": "07eedc54-f9aa-4376-ee45-ffc45679f138"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9523809523809523\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "# prediction on test set\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p6wUSYKqDDCE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "RandomForest.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
